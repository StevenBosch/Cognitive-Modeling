\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{listings}

\title{Memory Driven Temporal Preparation: A Cognitive Model}
 
\author{{\large \bf Steven Bosch (s1861948 - s.bosch.8@student.rug.nl)} \\
  Faculty of Mathematics and Natural Sciences}


\begin{document}
\maketitle

\begin{abstract}
A cognitive ability in humans is the ability of cue target interval timing. There are multiple theories on how humans approach such a problem. One such theories encompasses the \textit{hazard function}, which describes that the conditional probability of the occurence of a target event after the presentation of a cue increases over time, given that the event has not yet occurred. Los et al. (2014) developed the \textit{multiple trace theory of temporal preparation} (MTP) that states that every new trial causes a memory trace to be created, which influences the next trial. In an experiment they showed that this seems to be the case indeed. This study discusses a model that incorporates both the hazard function and the MTP. The model approached the experiment results to a certain extent, but falls short in some respects.

\textbf{Keywords:} 
temporal preparation; cue target interval timing; Hazard function; long term memory
\end{abstract}

\section{Introduction}
The human brain has many traits that we are hardly aware of during our everyday lives, even though these traits have a great impact on our experiences and actions. One such trait is the ability of cue target interval timing. Both consciously and unconsciously this ability is exercised in numerous situations, such as waiting for traffic lights, expecting a sound when something falls or simply expecting the second hand of a clock to move to the next second. What are the cognitive mechanisms behind this ability?

One theory encompasses the \textit{hazard function}. This function describes that the conditional probability of the occurrence of a target event after the presentation of a cue increases over time, given that the event has not yet occurred. While this function has been successfully used to predict interval timing behaviour \cite{Nobre, Vangkilde}, it does not provide an explanation as to the cognitive processes behind it. Moreover it does not take into account memory traces of preceding timing experiences. Over the past years research began on just this basis \cite{Los1, Howard, Taatgen}. Los et al. (2014) developed what they called the \textit{multiple trace theory of temporal preparation} (MTP), in which every new trial causes a memory trace to be created, storing a temporal profile of that trial. This memory trace subsequently contributes to the preparation of subsequent trials. 

A recent experiment by Los et al. indicated that temporal preparation is indeed driven by memory \cite{Los2}. In the experiment different groups of participants were presented with different distributions of foreperiods between temporal cues and target stimuli. Three of these experiments showed a transfer effect of this manipulation in a test phase where all participants received the same uniform distribution, indicating memory influence. 

This paper discusses a model that tries to capture (some of) the cognitive processes behind the phenomenon that the experiment by Los et al. (2015) brought to light. Using a cognitive model might give us more insight into he workings of this particular cognitive process.

\section{Experiment}
\subsection{Method}
In Los et al.'s (2015) experiment sixty-four students were randomly assigned to one of two groups, each consisting of 32 participants. The participants were asked to sit behind a computer screen with their left index finger on the \textit{z} key and their right index finger on the \textit{m} key. Each trial started with the appearance of a black plus sign, \textit{S1}, in the middle of the screen. Subsequently after a given foreperiod of either 400, 800, 1200 or 1600 ms a second signal, \textit{S2}, appeared. Seeing the signal, the participants had to press either \textit{z}, when \textit{S2} appeared left, or \textit{m} when \textit{S2} appeared right. They were instructed to perform this action as fast as they could. After the response the screen turned black and after an interval of 1.5 seconds the next trial would start.

Every participant had to complete 5 blocks of 120 trials each. The distribution of trials within a block was either uniform (30 trials of each foreperiod), exponential (64, 32, 16 and 8 trials for foreperiods of 400, 800, 1200 and 1600 ms respectively) or anti-exponential (8, 16, 32 and 64 trials for foreperiods of 400, 800, 1200 and 1600 ms respectively) distribution. Table \ref{Table1} shows the foreperiod distributions of the blocks per group. For both of the groups block 1, 4 and 5 were uniform, whereas block 2 and 3 were either exponential or anti-exponential.

In the experiment the participants were informed every block about their mean response time (RT) and the percentage of correct responses of that block. Furthermore after block 3 they were informed of the distributions of the preceding and succeeding two blocks.

\begin{table}
	\centering
	\caption{Successive foreperiod distributions across blocks for group 1 and 2 (Uni $=$ uniform, Exp $=$ exponential, Anti-exp $=$ anti-exponential).}
	\begin{tabular}{c|c|c|c|c|c}
		Block & 1 & 2 & 3 & 4 & 5 \\
		\hline
		Group 1 & Uni & Exp & Exp & Uni & Uni \\
		Group2 & Uni & Anti-exp & Anti-exp & Uni & Uni
	\end{tabular}
	\label{Table1}
\end{table}

\subsection{Results}
Figure \ref{LosFigure} shows the results of Los et al.'s experiment. Los et al. themselves applied a mixed Analysis of Variance (ANOVA) on the data of each block, with group and foreperiod as factors. They report a strong main effect of foreperiod in all blocks, $F (1, 62) \geq 58.63$ and $p < 0.001$. Furthermore they reported a significant main effect of group in block 2, $F (1, 62) = 13.81$, $p < 0.001$ and 3, $F(1, 62) = 13.95$, $p < 0.001$, but not in the other blocks. The interaction between group and foreperiod was not significant in block 1, $F(1, 62) < 1$, but it was in the other four blocks, with blocks 2 and 3 having $F (1, 62) \geq 69.64$, $p < 0.001$, and blocks 4 and 5 having $F (1, 62) \geq 13.12$ and $p \leq 0.001$.

Figure \ref{LosFigure} shows that for the first uniform distribution, when the participants do not have any prior experience with the experiment yet, their mean RT fore a foreperiod of 400 ms is around 360 ms. It decreases exponentially to around 320 ms for a foreperiod of 1600. In blocks 2 and 3 we see a clear difference between the exponential and anti-exponential distribution. The mean RT for the exponential group decreases greatly for shorter foreperiods, while the opposite happens for the anti-exponential group: the mean RT increases especially for the shorter foreperiods. In the final two blocks we can still see slight remnants of the preceding distributions, with slight differences between the two groups of participants (as discussed the interactino between group and foreperiod was significant in these blocks as well).

As discussed in the introduction, from these results it appears that the cognitive process of cue target interval timing involves more than just the hazard function. Indeed, otherwise there would have been no difference between the mean RTs of the different blocks. The results of this experiment clearly showed that the distribution of foreperiods does affect the anticipation of the second stimulus. When many short stimuli have appeared in the recent experiences of a participant, he will be more prone to react faster after a short foreperiod. Similarly when many long stimuli have appeared in his recent experiences, the response time is longer for all foreperiods, but especially for the shorter ones. This observation brings us to the cognitive model this study discusses.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{Los1.png}
	\caption{Los et al.'s experiment results of mean response time as a function of group, block and foreperiod. Illustration from Los et al. (2015).}
	\label{LosFigure}
\end{figure}

\section{Model}
\subsection{Method}
The model consists of a timing and memory function, which were built upon functions that are proposed earlier in the literature, and two components specifically designed for the current timing task. 

The timing function is modelled by \citet{Taatgen1} as an Act-R module, the `temporal module'.\footnote{Act-R is a cognitive architecture, see http://act-r.psy.cmu.edu/.}. This module models the idea that people internally measure an interval in number of ticks, which are counted with increasingly long intervals. Furthermore the model uses a declarative memory function (DM-module) that is proposed in \citet{Taatgen}, in which memories are stored as encounters of a specific chunk in the declarative memory. Subsequently the activation of every chunk is calculated to determine how `fresh' in memory it is, according to the following function:
\begin{equation}
	A(T) = log(\sum_{encs}(t - t_{enc})^{-d}))
\end{equation}
Here $t$ is the current time, $t_{enc}$ is the time when an encounter of that specific chunk is created and $d$ is a constant.

For this specific cue target interval timing problem there were two more main components that needed to be modelled, in order for the model to produce the results generated in the experiment:
\begin{enumerate}
	\item A hazard function
	\item Memory influence on the temporal preparation
\end{enumerate}
Let us discuss each of these separately.

\paragraph{The hazard function}
The hazard function is necessary, because the first block in the experiment clearly showed that without memory of past cue target timing experiences, the mean response times decrease logarithmically as the foreperiod becomes longer, down to a certain threshold.\footnote{Note that this study only discusses the time intervals discussed in Los et al.'s paper. Different mechanisms might come into play for shorter or longer intervals.} The Hazard function can be applied here: the longer it takes before the second signal is shown, the higher the probability becomes that it will come at the next millisecond. 

The fact that the plots show some sort of negative logarithmic function might be the result of a number of things. First, there is a limit to how fast a human being can respond: he has to observe the signal first, after which this image has to be processed and recognized. Finally the procedural step has to be taken to press the (right) button. Since all of these processes take time, it is logical that there is an asymptote that the response times approach as the participants become more prepared. They can never be faster than a certain speed. Second, a participant cannot expect the experiment to last forever. This makes it logical that the first milliseconds its expectation increases (so its response time decreases) at a higher rate than at a later time. 

Finally, one last assumption is made in modelling the hazard function: there is also a maximum response time. No matter how ill-prepared a participant may be for the second signal, he will still respond within a certain amount of time, unless of course he is distracted in one way or another.

The implementation of the Hazard function used in the model is the following:
\begin{equation}
	R = R_b + maxDelay * e^{-\frac{ticks^d}{m}}
\end{equation}
Here $R$ is the response time, $R_b$ the base response, maxDelay the maximum number of milliseconds a response can take, ticks the number of ticks counted during the foreperiod, and $d$ and $m$ parameters that depend on memory (see the next paragraph). This study uses a base response of 320 ms and a maximum delay of 150 ms, meaning that all of the responses fall within 320 and 470 ms. The exponential factor in the function makes sure that a longer foreperiod is always responded to more quickly than a shorter one. It depends on $d$ and $m$ what the magnitude of this difference is.

\paragraph{Memory influence}
From the results of the Los et al. experiment it appears that memory has a direct influence on the preparation rate for the second signal, so this had to implemented in the model as well. As we saw from the results, with more short intervals in memory a participant was prepared more quickly and responded faster to (primarily the short) intervals, with more long intervals in memory the participant would take longer to be prepared, which not only affected the short intervals, but even the long intervals (see figure \ref{LosFigure}, the graphs of the second and third block). One explanation for this phenomenon is that the participant unconsciously determines the probabilities of a trial being a short or long interval dependent on the distribution of intervals it has in its memory. Dependent on this estimate the participant would either prepare himself for a short interval or `wait a while' before there was a need to prepare himself. 

The participants probably did not experience a sense of exact knowledge concerning the distribution of foreperiods in the block they were in, but they probably did have a more general sense of the foreperiods being predominantly shorter or longer in their past experiences. In this model it is assumed that these were the two options, together with `being about equal', that the human cognition assigned to the foreperiod distribution: predominantly short, about equal, or predominantly long.
This is modelled in the following way. Using the activation of the chunks in the DM-module (as described above), the prior probability of every encountered foreperiod (in `ticks') is calculated, based on all the encounters per foreperiod. Since the foreperiods are converted to ticks, which is a noisy process, multiple chunks can represent the same foreperiod. Using these prior probabilities, a combined probability on all the shorter foreperiod encounters is calculated as:
\begin{equation}
	P(short) = \sum_{i = 0}^{i = m} P_i
\end{equation}
in which $i$ is the number of ticks and $m$ is the maximum number of ticks that falls under `short' interval. One would consider this to be noisy, but since the conversion from time to ticks is already a noisy process, this parameter was hard coded.

Using this probability the reaction time was now calculated using the function described in the previous paragraph, with the following rules:
\begin{itemize}
	\item if $P(short) < T_1$: use $d_1$ and $m_1$
	\item else if $P(short) < T_2$: use $d_2$ and $m_2$
	\item else use $d_3$ and $m_3$
\end{itemize}
These rules say the following: if there is a low probability on a short interval (lower than the first threshold $T_1$), use the parameters $d_1$ and $m_1$, or in human terms: take the time in preparing for the second signal. If this is not the case and the probability is about half for either short or long intervals ($T_1 \leq P(short) < T_2$), use the parameters $d_2$ and $m_2$ (or `both could happen, just do standard preparation'). Finally if that is not the case, meaning there is a higher probability on short intervals ($T_2 \leq P(short)$), use parameters $d_3$ and $m_3$ (`prepare for the second signal quickly').
\bigskip

\noindent These functions were combined into a model that has to do the same actions as the human participants did. Just as in the Los et al.'s experiment this experiment was run with two groups of 32 `participants' each, with the same foreperiod distributions per group.

\subsection{Results}
\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{5blocks2.png}
	\caption{Model results of mean response time as a function of group, block and foreperiod.}
	\label{5blocks}
\end{figure}
Figure \ref{5blocks} shows the mean RT of the model as function of foreperiod, group and block. We applied an ANOVA on the data of every block, with foreperiod and group as factors. As with the experiment of Los et al. the ANOVA shows a strong main effect of foreperiod in all blocks, $F(1,64) \geq 86.38$, $p < 0.001$. Apart from the first block, all blocks show a strong main effect of group as well, $F(1,64) \geq 42.91$, $p < 0.001$. Finally apart from the first block, all blocks show a strong main effect of the interaction between group and foreperiod, $F(1,64) \geq 344.4$, $p < 0.001$.

The figure and ANOVA results shows that in the first block both of the groups yield approximately the same response times. For the latter four blocks this is not the case however, for these blocks the ANOVA tested significant differences between the two groups. From the figure we can see that group 1, which got the exponential distributions (so mostly short intervals) responded faster to the short intervals, especially in the third and fourth block, in which there is little difference between the response times for short and long foreperiods ($\leq 10 ms$). Group 2, who got the anti-exponential distributions, responded slower in blocks 2-4, especially so when given short foreperiods, but slightly for long foreperiods as well. In the last block we see the two groups having almost the same response times again (although the difference was significant as mentioned above).

\section{Discussion}
Comparing the results, we can observe that the model approximates the experiment results well in some areas, while in others it does not.


\bibliographystyle{apacite}
\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}
\bibliography{bibliography}

\end{document}
